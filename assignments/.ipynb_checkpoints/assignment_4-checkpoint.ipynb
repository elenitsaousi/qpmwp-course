{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4\n",
    "\n",
    "Deadline: 30.04.2025 12:00 CET\n",
    "\n",
    "<Add your name, student-id and emal address>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites: Library imports, data load and initialization of the backtest service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "from typing import Optional\n",
    "\n",
    "# Third party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Add the project root directory to Python path\n",
    "project_root = \"/Users/elenetsaouse/qpmwp-course\"\n",
    "sys.path.append(\"/Users/elenetsaouse/qpmwp-course/qpmwp-course/src\")\n",
    "   # Change this path if needed\n",
    "src_path = os.path.join(project_root, 'qpmwp-course\\\\src')\n",
    "sys.path.append(project_root)\n",
    "sys.path.append(src_path)\n",
    "\n",
    "# Local modules imports\n",
    "from helper_functions import load_data_spi, load_pickle\n",
    "from estimation.covariance import Covariance\n",
    "from estimation.expected_return import ExpectedReturn\n",
    "from optimization.optimization import Optimization, Objective, MeanVariance\n",
    "from optimization.optimization_data import OptimizationData\n",
    "from optimization.constraints import Constraints\n",
    "from backtesting.backtest_item_builder_classes import (\n",
    "    SelectionItemBuilder,\n",
    "    OptimizationItemBuilder,\n",
    ")\n",
    "from backtesting.backtest_item_builder_functions import (\n",
    "    bibfn_selection_min_volume,\n",
    "    bibfn_selection_gaps,\n",
    "    bibfn_return_series,\n",
    "    bibfn_budget_constraint,\n",
    "    bibfn_box_constraints,\n",
    "    bibfn_size_dependent_upper_bounds,\n",
    ")\n",
    "from backtesting.backtest_data import BacktestData\n",
    "from backtesting.backtest_service import BacktestService\n",
    "from backtesting.backtest import Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/elenetsaouse/qpmwp-course/qpmwp-course/data/market_data.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m path_to_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/elenetsaouse/qpmwp-course/qpmwp-course/data\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# <change this to your path to data>\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load market and jkp data from parquet files\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m market_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_to_data\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/market_data.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parquet.py:667\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    665\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m--> 667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m impl\u001b[38;5;241m.\u001b[39mread(\n\u001b[1;32m    668\u001b[0m     path,\n\u001b[1;32m    669\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m    670\u001b[0m     filters\u001b[38;5;241m=\u001b[39mfilters,\n\u001b[1;32m    671\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    672\u001b[0m     use_nullable_dtypes\u001b[38;5;241m=\u001b[39muse_nullable_dtypes,\n\u001b[1;32m    673\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    674\u001b[0m     filesystem\u001b[38;5;241m=\u001b[39mfilesystem,\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    676\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parquet.py:267\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    265\u001b[0m     to_pandas_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit_blocks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m path_or_handle, handles, filesystem \u001b[38;5;241m=\u001b[39m _get_path_or_handle(\n\u001b[1;32m    268\u001b[0m     path,\n\u001b[1;32m    269\u001b[0m     filesystem,\n\u001b[1;32m    270\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    271\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    272\u001b[0m )\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[1;32m    275\u001b[0m         path_or_handle,\n\u001b[1;32m    276\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    280\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parquet.py:140\u001b[0m, in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m    130\u001b[0m handles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m     handles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m    141\u001b[0m         path_or_handle, mode, is_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, storage_options\u001b[38;5;241m=\u001b[39mstorage_options\n\u001b[1;32m    142\u001b[0m     )\n\u001b[1;32m    143\u001b[0m     fs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     path_or_handle \u001b[38;5;241m=\u001b[39m handles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/elenetsaouse/qpmwp-course/qpmwp-course/data/market_data.parquet'"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "path_to_data = '/Users/elenetsaouse/qpmwp-course/qpmwp-course/data'  # <change this to your path to data>\n",
    "\n",
    "# Load market and jkp data from parquet files\n",
    "market_data = pd.read_parquet(f'{path_to_data}/market_data.parquet')\n",
    "\n",
    "\n",
    "# Instantiate the BacktestData class\n",
    "# and set the market data and jkp data as attributes\n",
    "data = BacktestData()\n",
    "data.market_data = market_data\n",
    "data.bm_series = load_data_spi(path='/Users/elenetsaouse/qpmwp-course/qpmwp-course/data/spi_index.csv') # <change this if necessary>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'market_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Define rebalancing dates\u001b[39;00m\n\u001b[1;32m      2\u001b[0m n_days \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m21\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3\u001b[39m\n\u001b[0;32m----> 3\u001b[0m market_data_dates \u001b[38;5;241m=\u001b[39m market_data\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_level_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39munique()\u001b[38;5;241m.\u001b[39msort_values(ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m rebdates \u001b[38;5;241m=\u001b[39m market_data_dates[market_data_dates \u001b[38;5;241m>\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2015-01-01\u001b[39m\u001b[38;5;124m'\u001b[39m][::n_days]\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'market_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Define rebalancing dates\n",
    "n_days = 21*3\n",
    "market_data_dates = market_data.index.get_level_values('date').unique().sort_values(ascending=True)\n",
    "rebdates = market_data_dates[market_data_dates > '2015-01-01'][::n_days].strftime('%Y-%m-%d').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the selection item builders.\n",
    "selection_item_builders = {\n",
    "    'gaps': SelectionItemBuilder(\n",
    "        bibfn = bibfn_selection_gaps,\n",
    "        width = 252*3,\n",
    "        n_days = 10,\n",
    "    ),\n",
    "    'min_volume': SelectionItemBuilder(\n",
    "        bibfn = bibfn_selection_min_volume,\n",
    "        width = 252,\n",
    "        min_volume = 500_000,\n",
    "        agg_fn = np.median,\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Define the optimization item builders.\n",
    "optimization_item_builders = {\n",
    "    'return_series': OptimizationItemBuilder(\n",
    "        bibfn = bibfn_return_series,\n",
    "        width = 252*3,\n",
    "        fill_value = 0,\n",
    "    ),\n",
    "    'budget_constraint': OptimizationItemBuilder(\n",
    "        bibfn = bibfn_budget_constraint,\n",
    "        budget = 1,\n",
    "    ),\n",
    "    'box_constraints': OptimizationItemBuilder(\n",
    "        bibfn = bibfn_box_constraints,\n",
    "        upper = 0.1,\n",
    "    ),\n",
    "    'size_dep_upper_bounds': OptimizationItemBuilder(\n",
    "        bibfn = bibfn_size_dependent_upper_bounds,\n",
    "        small_cap = {'threshold': 300_000_000, 'upper': 0.02},\n",
    "        mid_cap = {'threshold': 1_000_000_000, 'upper': 0.05},\n",
    "        large_cap = {'threshold': 10_000_000_000, 'upper': 0.1},\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Initialize the backtest service\n",
    "bs = BacktestService(\n",
    "    data = data,\n",
    "    selection_item_builders = selection_item_builders,\n",
    "    optimization_item_builders = optimization_item_builders,\n",
    "    rebdates = rebdates,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Maximum Sharpe Ratio Portfolio\n",
    "\n",
    "a) \n",
    "\n",
    "(6 points)\n",
    "\n",
    "Complete the `MaxSharpe` class below by implementing your its methods `set_objective` and `solve`.\n",
    "The `solve` method should implement an iterative algorithm that quickly approximates the \"true\" maximimum Sharpe ratio portfolio (given the estimates of mean and covariance). This approximation should be done by repeatedly solving a mean-variance optimization problem, where the risk aversion parameter (which scales the covariance matrix) is adjusted in each iteration. The algorithm should terminate after a maximum of 10 iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxSharpe(Optimization):\n",
    "\n",
    "    def __init__(self,\n",
    "                 constraints: Optional[Constraints] = None,\n",
    "                 covariance: Optional[Covariance] = None,\n",
    "                 expected_return: Optional[ExpectedReturn] = None,\n",
    "                 **kwargs) -> None:\n",
    "        super().__init__(\n",
    "            constraints=constraints,\n",
    "            **kwargs,\n",
    "        )\n",
    "        self.covariance = Covariance() if covariance is None else covariance\n",
    "        self.expected_return = ExpectedReturn() if expected_return is None else expected_return\n",
    "\n",
    "    def set_objective(self, optimization_data: OptimizationData) -> None:\n",
    "        #<your code here>\n",
    "        return None\n",
    "\n",
    "    def solve(self) -> None:\n",
    "        #<your code here>\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) \n",
    "\n",
    "(2 points)\n",
    "\n",
    "Provide a theoretical or empirical justification that your algorithm converges to the true maximum Sharpe ratio portfolio for the given coefficients of mean and covariance.\n",
    "Hint: If you want to provide an empirical justification, you can perform an optimization for a single point in time by running the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs.optimization = MaxSharpe(\n",
    "#     covariance=Covariance(method='pearson'),\n",
    "#     expected_return=ExpectedReturn(method='geometric'),\n",
    "#     solver_name='cvxopt',  # <change this to your preferred solver>\n",
    "#     #<add any other parameters you need, e.g., number of iterations, tolerance, etc.>\n",
    "# )\n",
    "# bs.prepare_rebalancing('2015-01-02')\n",
    "# bs.optimization.set_objective(bs.optimization_data)\n",
    "# bs.optimization.solve()\n",
    "# bs.optimization.results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Backtest MaxSharpe with Turnover Penalty\n",
    "\n",
    "(5 points)\n",
    "\n",
    "Calibrate the turnover penalty parameter such that the backtest of the MaxSharpe strategy displays an annual turnover of roughly 100%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the backtest service with a MaxSharpe optimization object\n",
    "bs.optimization = MaxSharpe(\n",
    "    covariance=Covariance(method='pearson'),\n",
    "    expected_return=ExpectedReturn(method='geometric'),\n",
    "    solver_name='cvxopt',    # <change this to your preferred solver>\n",
    "    turnover_penalty=None,   # <change this>\n",
    ")\n",
    "\n",
    "# Instantiate the backtest object\n",
    "bt_ms = Backtest()\n",
    "\n",
    "# Run the backtest\n",
    "bt_ms.run(bs = bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Simulation and Descriptive Statistics\n",
    "\n",
    "(3 points)\n",
    "\n",
    "- Simulate the portfolio returns from your MaxSharpe backtest. Use fixed costs of 1% and variable costs of 0.3%.\n",
    "- Plot the cumulated returns of the MaxSharpe strategy together with those of the SPI Index.\n",
    "- Plot the turnover of your MaxSharpe strategy over time.\n",
    "- Print the annualized turnover (computed as the average turnover over the backtest multiplied by the number of rebalancing per year) for your MaxSharpe strategy.\n",
    "- Create and print a table with descriptive performance statistics for your MaxSharpe strategy and the SPI Index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<your code here>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
